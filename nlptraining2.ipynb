{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlptraining2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNHaGF/7qAXe3lY+QbwNNJe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BERGASPAMUNGKAS01/python-sma/blob/master/nlptraining2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ldcJJmmACAd",
        "outputId": "0433d01d-813a-44ca-db91-42e10f9fd53f"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('book')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'book'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection book\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw4GM9Rc-uEm",
        "outputId": "3b4ab998-fce0-4b79-95eb-321b2f76f153"
      },
      "source": [
        ">>> import nltk\r\n",
        ">>> nltk.corpus.gutenberg.fileids()\r\n",
        "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt',\r\n",
        "'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt',\r\n",
        "'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt',\r\n",
        "'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt',\r\n",
        "'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt',\r\n",
        "'shakespeare-macbeth.txt', 'whitman-leaves.txt']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVVjUTEQ_74D",
        "outputId": "1240aad2-385a-480b-ebd6-49dba1a3d53d"
      },
      "source": [
        ">>> emma = nltk.corpus.gutenberg.words('austen-emma.txt')\r\n",
        ">>> len(emma)\r\n",
        "192427"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "192427"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XnbMsmO_9Ee",
        "outputId": "ce84088f-256a-459d-9ef1-3412ecd49e24"
      },
      "source": [
        ">>> emma = nltk.Text(nltk.corpus.gutenberg.words('austen-emma.txt'))\r\n",
        ">>> emma.concordance(\"surprize\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Displaying 25 of 37 matches:\n",
            "er father , was sometimes taken by surprize at his being still able to pity ` \n",
            "hem do the other any good .\" \" You surprize me ! Emma must do Harriet good : a\n",
            "Knightley actually looked red with surprize and displeasure , as he stood up ,\n",
            "r . Elton , and found to his great surprize , that Mr . Elton was actually on \n",
            "d aid .\" Emma saw Mrs . Weston ' s surprize , and felt that it must be great ,\n",
            "father was quite taken up with the surprize of so sudden a journey , and his f\n",
            "y , in all the favouring warmth of surprize and conjecture . She was , moreove\n",
            "he appeared , to have her share of surprize , introduction , and pleasure . Th\n",
            "ir plans ; and it was an agreeable surprize to her , therefore , to perceive t\n",
            "talking aunt had taken me quite by surprize , it must have been the death of m\n",
            "f all the dialogue which ensued of surprize , and inquiry , and congratulation\n",
            " the present . They might chuse to surprize her .\" Mrs . Cole had many to agre\n",
            "the mode of it , the mystery , the surprize , is more like a young woman ' s s\n",
            " to her song took her agreeably by surprize -- a second , slightly but correct\n",
            "\" \" Oh ! no -- there is nothing to surprize one at all .-- A pretty fortune ; \n",
            "t to be considered . Emma ' s only surprize was that Jane Fairfax should accep\n",
            "of your admiration may take you by surprize some day or other .\" Mr . Knightle\n",
            "ation for her will ever take me by surprize .-- I never had a thought of her i\n",
            " expected by the best judges , for surprize -- but there was great joy . Mr . \n",
            " sound of at first , without great surprize . \" So unreasonably early !\" she w\n",
            "d Frank Churchill , with a look of surprize and displeasure .-- \" That is easy\n",
            "; and Emma could imagine with what surprize and mortification she must be retu\n",
            "tled that Jane should go . Quite a surprize to me ! I had not the least idea !\n",
            " . It is impossible to express our surprize . He came to speak to his father o\n",
            "g engaged !\" Emma even jumped with surprize ;-- and , horror - struck , exclai\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNOyT4T2AsnW",
        "outputId": "c153b499-8029-44bd-d7f6-c16cb7a07325"
      },
      "source": [
        ">>> from nltk.corpus import nps_chat\r\n",
        ">>> chatroom = nps_chat.posts('10-19-20s_706posts.xml')\r\n",
        ">>> chatroom[123]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'do',\n",
              " \"n't\",\n",
              " 'want',\n",
              " 'hot',\n",
              " 'pics',\n",
              " 'of',\n",
              " 'a',\n",
              " 'female',\n",
              " ',',\n",
              " 'I',\n",
              " 'can',\n",
              " 'look',\n",
              " 'in',\n",
              " 'a',\n",
              " 'mirror',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xSnd0CmDuNn",
        "outputId": "eb00aef6-9b12-4919-97e2-be878af9479d"
      },
      "source": [
        ">>> from nltk.corpus import brown\r\n",
        ">>> brown.categories()\r\n",
        "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies',\r\n",
        "'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance',\r\n",
        "'science_fiction']"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adventure',\n",
              " 'belles_lettres',\n",
              " 'editorial',\n",
              " 'fiction',\n",
              " 'government',\n",
              " 'hobbies',\n",
              " 'humor',\n",
              " 'learned',\n",
              " 'lore',\n",
              " 'mystery',\n",
              " 'news',\n",
              " 'religion',\n",
              " 'reviews',\n",
              " 'romance',\n",
              " 'science_fiction']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv1I_yVcDzU-",
        "outputId": "5c5d01b1-feca-4663-892d-9358c9b4e8a3"
      },
      "source": [
        ">>> cfd = nltk.ConditionalFreqDist(\r\n",
        "... (genre, word)\r\n",
        "... for genre in brown.categories()\r\n",
        "... for word in brown.words(categories=genre))\r\n",
        ">>> genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\r\n",
        ">>> modals = ['can', 'could', 'may', 'might', 'must', 'will']\r\n",
        ">>> cfd.tabulate(conditions=genres, samples=modals)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  can could   may might  must  will \n",
            "           news    93    86    66    38    50   389 \n",
            "       religion    82    59    78    12    54    71 \n",
            "        hobbies   268    58   131    22    83   264 \n",
            "science_fiction    16    49     4    12     8    16 \n",
            "        romance    74   193    11    51    45    43 \n",
            "          humor    16    30     8     8     9    13 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCbfy8SqEFXi",
        "outputId": "f28d30ba-0ced-4e06-ebd8-9b8113b0cd46"
      },
      "source": [
        ">>> from nltk.corpus import wordnet as wn\r\n",
        ">>> wn.synsets('motorcar')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('car.n.01')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a29aMM6FEdjQ",
        "outputId": "bf4246ca-afe9-4831-f12c-853f13dcfada"
      },
      "source": [
        ">>> wn.synset('car.n.01').lemma_names\r\n",
        "['car', 'auto', 'automobile', 'machine', 'motorcar']"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['car', 'auto', 'automobile', 'machine', 'motorcar']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA-KJkSoEiti",
        "outputId": "66ada122-6cb4-4e64-f81e-4b144826fa81"
      },
      "source": [
        ">>> wn.synset('car.n.01').definition\r\n",
        "'a motor vehicle with four wheels; usually propelled by an internal combustion engine'\r\n",
        ">>> wn.synset('car.n.01').examples\r\n",
        "['he needs a car to get to work']"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['he needs a car to get to work']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4v2gtpEElY3",
        "outputId": "6e3ef614-0bb2-44f7-a217-32504e09344e"
      },
      "source": [
        ">>> wn.synset('baleen_whale.n.01').min_depth()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BTd_MGEFEyn",
        "outputId": "66ce4a6d-0686-4b3f-b60e-0e9d6066aff3"
      },
      "source": [
        ">>> wn.synset('whale.n.02').min_depth()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbdfODvMFIlT",
        "outputId": "2b3d5d50-70a5-4cb3-a0bb-89584186a8b1"
      },
      "source": [
        ">>> wn.synset('vertebrate.n.01').min_depth()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tEemyEgFK1H",
        "outputId": "4cad01f3-72cd-4478-acda-5c557c825e3b"
      },
      "source": [
        ">>> wn.synset('entity.n.01').min_depth()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    }
  ]
}